{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpectrumRegressionFramework.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9bptQ9GxO0p",
        "colab_type": "code",
        "outputId": "daf5a22e-a9df-4acb-f4fe-d5da8ebf72b5",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "a = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1ee19005-6ed1-4d90-b305-f314fdf94d78\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-1ee19005-6ed1-4d90-b305-f314fdf94d78\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving BananaVIS.csv to BananaVIS.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAuYjuq40dVL",
        "colab_type": "code",
        "outputId": "6c0c47ef-369a-4f83-e345-2d4a3fb91c1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import diff\n",
        "import random\n",
        "%matplotlib inline\n",
        "import shutil\n",
        "import tensorflow.contrib.learn as tflearn\n",
        "import tensorflow.contrib.layers as tflayers\n",
        "from tensorflow.contrib.learn.python.learn import learn_runner\n",
        "import tensorflow.contrib.metrics as metrics\n",
        "import tensorflow.contrib.rnn as rnn\n",
        "from sklearn.model_selection import train_test_split\n",
        "!git clone https://github.com/EBjerrum/Deep-Chemometrics.git\n",
        "  \n",
        "def dataaugment(x, betashift = 0.05, slopeshift = 0.05,multishift = 0.05):\n",
        "    #Shift of baseline\n",
        "    #calculate arrays\n",
        "    beta = np.random.random(size=(x.shape[0],1))*2*betashift-betashift\n",
        "    slope = np.random.random(size=(x.shape[0],1))*2*slopeshift-slopeshift + 1\n",
        "    #Calculate relative position\n",
        "    axis = np.array(range(x.shape[1]))/float(x.shape[1])\n",
        "    #Calculate offset to be added\n",
        "    offset = slope*(axis) + beta - axis - slope/2. + 0.5\n",
        "\n",
        "    #Multiplicative\n",
        "    multi = np.random.random(size=(x.shape[0],1))*2*multishift-multishift + 1\n",
        "\n",
        "    x = multi*x + offset\n",
        "\n",
        "    return x\n",
        "  \n",
        "data = pd.read_csv('BananaVIS.csv')\n",
        "\n",
        "spectrums= np.array(data.values[:, 0:288],dtype = np.int32)\n",
        "categories=np.array(data.values[:,-1],dtype=np.int32)\n",
        "portion = int(4/5 *spectrums.shape[0])\n",
        "\n",
        "#Split train and test set\n",
        "x_train, x_test, y_train,y_test = train_test_split(spectrums[:portion],categories[:portion],test_size=0.2,random_state=42)\n",
        "\n",
        "x_check = spectrums[portion:]\n",
        "y_check = categories[portion:]\n",
        "\n",
        "%cd Deep-Chemometrics\n",
        "\n",
        "from ChemUtils import GlobalStandardScaler\n",
        "\n",
        "xscaler = GlobalStandardScaler()\n",
        "x_train = xscaler.fit_transform(x_train) \n",
        "x_test = xscaler.transform(x_test) \n",
        "x_check = xscaler.transform(x_check)\n",
        "\n",
        "yscaler = GlobalStandardScaler()\n",
        "y_train = yscaler.fit_transform(y_train)\n",
        "y_test = yscaler.transform(y_test)\n",
        "y_check = yscaler.transform(y_check)\n",
        "\n",
        "#EMSC rescaling\n",
        "from ChemUtils import EmscScaler\n",
        "emsc = EmscScaler()\n",
        "emsc.fit(x_train)\n",
        "X_train_emsc = emsc.transform((x_train))\n",
        "X_test_emsc = emsc.transform(x_test)\n",
        "X_check_emsc = emsc.transform(x_check)\n",
        "\n",
        "#Data Augment a single spectrum\n",
        "\n",
        "#First Spectrum\n",
        "X = x_test[0:1]\n",
        "#Repeating the spectrum 10x\n",
        "X = np.repeat(X, repeats=10, axis=0)\n",
        "#Augment (Large pertubations for illustration)\n",
        "X_aug = dataaugment(X,betashift = 0.5, slopeshift = 0.5,multishift = 0.5)\n",
        "shift = np.std(x_train)*0.1\n",
        "X_train_aug = np.repeat(X_train_emsc, repeats=1000, axis=0)\n",
        "X_train_aug = dataaugment(X_train_aug, betashift = shift, slopeshift = 0.05, multishift = shift)\n",
        "y_train_aug = np.repeat(y_train, repeats=1000, axis=0) #y_train is simply repeated\n",
        "\n",
        "shift = np.std(x_test)*0.1\n",
        "X_test_aug = np.repeat(X_test_emsc, repeats=5000, axis=0)\n",
        "X_test_aug = dataaugment(X_test_aug, betashift = shift, slopeshift = 0.05, multishift = shift)\n",
        "y_test_aug = np.repeat(y_test, repeats=5000, axis=0) #y_test is simply repeated\n",
        "\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv1D, Reshape, GaussianNoise, MaxPooling1D\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "#Hyperparameters for the network\n",
        "DENSE = 128\n",
        "DROPOUT = 0.5\n",
        "C1_K  = 128 #Number of kernels/feature extractors for first layer\n",
        "C1_S  = 64 #Width of the convolutional mini networks\n",
        "C2_K  = 64\n",
        "C2_S  = 32\n",
        "activation='relu'\n",
        "\n",
        "input_dim = x_train.shape[1]\n",
        "\n",
        "#The model\n",
        "def make_model():\n",
        "    model = Sequential()\n",
        "    #Adding a bit of GaussianNoise also works as regularization\n",
        "    #First two is number of filter + kernel size\n",
        "    model.add(Dense(128, kernel_initializer='normal',input_dim = input_dim, activation='relu'))\n",
        "    model.add(Dense(128, kernel_initializer='normal',activation='relu'))\n",
        "    model.add(Dense(128, kernel_initializer='normal',activation='relu'))\n",
        "    model.add(Dense(128, kernel_initializer='normal',activation='relu'))\n",
        "    model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
        "\n",
        "    model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
        "\n",
        "    return model\n",
        "  \n",
        "model = make_model()\n",
        "\n",
        "h = model.fit(X_train_aug, y_train_aug, epochs=50, batch_size=1024, validation_data=(X_test_aug, y_test_aug))\n",
        "\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "files.download('model.h5') \n",
        "files.download('model.json') \n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Deep-Chemometrics'...\n",
            "remote: Enumerating objects: 43, done.\u001b[K\n",
            "remote: Total 43 (delta 0), reused 0 (delta 0), pack-reused 43\u001b[K\n",
            "Unpacking objects: 100% (43/43), done.\n",
            "/content/Deep-Chemometrics\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0814 09:44:47.461953 139666592450432 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0814 09:44:47.469232 139666592450432 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0814 09:44:47.478594 139666592450432 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "W0814 09:44:47.545030 139666592450432 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0814 09:44:47.718768 139666592450432 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "W0814 09:44:47.980295 139666592450432 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 108000 samples, validate on 140000 samples\n",
            "Epoch 1/50\n",
            "108000/108000 [==============================] - 3s 32us/step - loss: 0.6381 - mean_absolute_error: 0.6381 - val_loss: 0.5892 - val_mean_absolute_error: 0.5892\n",
            "Epoch 2/50\n",
            "108000/108000 [==============================] - 3s 25us/step - loss: 0.3948 - mean_absolute_error: 0.3948 - val_loss: 0.6164 - val_mean_absolute_error: 0.6164\n",
            "Epoch 3/50\n",
            "108000/108000 [==============================] - 3s 25us/step - loss: 0.3169 - mean_absolute_error: 0.3169 - val_loss: 0.5386 - val_mean_absolute_error: 0.5386\n",
            "Epoch 4/50\n",
            "108000/108000 [==============================] - 2s 23us/step - loss: 0.2590 - mean_absolute_error: 0.2590 - val_loss: 0.5232 - val_mean_absolute_error: 0.5232\n",
            "Epoch 5/50\n",
            "108000/108000 [==============================] - 3s 25us/step - loss: 0.2233 - mean_absolute_error: 0.2233 - val_loss: 0.5759 - val_mean_absolute_error: 0.5759\n",
            "Epoch 6/50\n",
            "108000/108000 [==============================] - 3s 25us/step - loss: 0.1837 - mean_absolute_error: 0.1837 - val_loss: 0.5328 - val_mean_absolute_error: 0.5328\n",
            "Epoch 7/50\n",
            "108000/108000 [==============================] - 3s 26us/step - loss: 0.1760 - mean_absolute_error: 0.1760 - val_loss: 0.6133 - val_mean_absolute_error: 0.6133\n",
            "Epoch 8/50\n",
            "108000/108000 [==============================] - 3s 25us/step - loss: 0.1442 - mean_absolute_error: 0.1442 - val_loss: 0.6176 - val_mean_absolute_error: 0.6176\n",
            "Epoch 9/50\n",
            "108000/108000 [==============================] - 3s 25us/step - loss: 0.1532 - mean_absolute_error: 0.1532 - val_loss: 0.6269 - val_mean_absolute_error: 0.6269\n",
            "Epoch 10/50\n",
            "108000/108000 [==============================] - 3s 25us/step - loss: 0.1147 - mean_absolute_error: 0.1147 - val_loss: 0.5417 - val_mean_absolute_error: 0.5417\n",
            "Epoch 11/50\n",
            "108000/108000 [==============================] - 3s 26us/step - loss: 0.1000 - mean_absolute_error: 0.1000 - val_loss: 0.4966 - val_mean_absolute_error: 0.4966\n",
            "Epoch 12/50\n",
            "108000/108000 [==============================] - 2s 22us/step - loss: 0.1009 - mean_absolute_error: 0.1009 - val_loss: 0.5094 - val_mean_absolute_error: 0.5094\n",
            "Epoch 13/50\n",
            "108000/108000 [==============================] - 2s 21us/step - loss: 0.0959 - mean_absolute_error: 0.0959 - val_loss: 0.4898 - val_mean_absolute_error: 0.4898\n",
            "Epoch 14/50\n",
            "108000/108000 [==============================] - 3s 25us/step - loss: 0.0844 - mean_absolute_error: 0.0844 - val_loss: 0.5301 - val_mean_absolute_error: 0.5301\n",
            "Epoch 15/50\n",
            "108000/108000 [==============================] - 3s 27us/step - loss: 0.0912 - mean_absolute_error: 0.0912 - val_loss: 0.5980 - val_mean_absolute_error: 0.5980\n",
            "Epoch 16/50\n",
            "108000/108000 [==============================] - 3s 25us/step - loss: 0.0809 - mean_absolute_error: 0.0809 - val_loss: 0.5470 - val_mean_absolute_error: 0.5470\n",
            "Epoch 17/50\n",
            "108000/108000 [==============================] - 3s 26us/step - loss: 0.0728 - mean_absolute_error: 0.0728 - val_loss: 0.5410 - val_mean_absolute_error: 0.5410\n",
            "Epoch 18/50\n",
            "108000/108000 [==============================] - 3s 26us/step - loss: 0.0839 - mean_absolute_error: 0.0839 - val_loss: 0.5604 - val_mean_absolute_error: 0.5604\n",
            "Epoch 19/50\n",
            "108000/108000 [==============================] - 3s 26us/step - loss: 0.0559 - mean_absolute_error: 0.0559 - val_loss: 0.5145 - val_mean_absolute_error: 0.5145\n",
            "Epoch 20/50\n",
            "108000/108000 [==============================] - 3s 26us/step - loss: 0.0725 - mean_absolute_error: 0.0725 - val_loss: 0.5187 - val_mean_absolute_error: 0.5187\n",
            "Epoch 21/50\n",
            "108000/108000 [==============================] - 3s 28us/step - loss: 0.0639 - mean_absolute_error: 0.0639 - val_loss: 0.5220 - val_mean_absolute_error: 0.5220\n",
            "Epoch 22/50\n",
            "108000/108000 [==============================] - 3s 27us/step - loss: 0.0493 - mean_absolute_error: 0.0493 - val_loss: 0.5303 - val_mean_absolute_error: 0.5303\n",
            "Epoch 23/50\n",
            "108000/108000 [==============================] - 3s 26us/step - loss: 0.0653 - mean_absolute_error: 0.0653 - val_loss: 0.5885 - val_mean_absolute_error: 0.5885\n",
            "Epoch 24/50\n",
            "108000/108000 [==============================] - 3s 26us/step - loss: 0.0572 - mean_absolute_error: 0.0572 - val_loss: 0.4920 - val_mean_absolute_error: 0.4920\n",
            "Epoch 25/50\n",
            "108000/108000 [==============================] - 3s 27us/step - loss: 0.0538 - mean_absolute_error: 0.0538 - val_loss: 0.5463 - val_mean_absolute_error: 0.5463\n",
            "Epoch 26/50\n",
            "108000/108000 [==============================] - 3s 26us/step - loss: 0.0420 - mean_absolute_error: 0.0420 - val_loss: 0.5490 - val_mean_absolute_error: 0.5490\n",
            "Epoch 27/50\n",
            "108000/108000 [==============================] - 3s 27us/step - loss: 0.0435 - mean_absolute_error: 0.0435 - val_loss: 0.5449 - val_mean_absolute_error: 0.5449\n",
            "Epoch 28/50\n",
            "108000/108000 [==============================] - 3s 26us/step - loss: 0.0552 - mean_absolute_error: 0.0552 - val_loss: 0.5877 - val_mean_absolute_error: 0.5877\n",
            "Epoch 29/50\n",
            "108000/108000 [==============================] - 3s 27us/step - loss: 0.0412 - mean_absolute_error: 0.0412 - val_loss: 0.5057 - val_mean_absolute_error: 0.5057\n",
            "Epoch 30/50\n",
            "108000/108000 [==============================] - 3s 28us/step - loss: 0.0375 - mean_absolute_error: 0.0375 - val_loss: 0.5499 - val_mean_absolute_error: 0.5499\n",
            "Epoch 31/50\n",
            "108000/108000 [==============================] - 3s 29us/step - loss: 0.0341 - mean_absolute_error: 0.0341 - val_loss: 0.5570 - val_mean_absolute_error: 0.5570\n",
            "Epoch 32/50\n",
            "108000/108000 [==============================] - 3s 29us/step - loss: 0.0377 - mean_absolute_error: 0.0377 - val_loss: 0.5390 - val_mean_absolute_error: 0.5390\n",
            "Epoch 33/50\n",
            "108000/108000 [==============================] - 3s 28us/step - loss: 0.0384 - mean_absolute_error: 0.0384 - val_loss: 0.5643 - val_mean_absolute_error: 0.5643\n",
            "Epoch 34/50\n",
            "108000/108000 [==============================] - 3s 28us/step - loss: 0.0356 - mean_absolute_error: 0.0356 - val_loss: 0.5675 - val_mean_absolute_error: 0.5675\n",
            "Epoch 35/50\n",
            "108000/108000 [==============================] - 3s 29us/step - loss: 0.0364 - mean_absolute_error: 0.0364 - val_loss: 0.5119 - val_mean_absolute_error: 0.5119\n",
            "Epoch 36/50\n",
            "108000/108000 [==============================] - 3s 30us/step - loss: 0.0363 - mean_absolute_error: 0.0363 - val_loss: 0.5392 - val_mean_absolute_error: 0.5392\n",
            "Epoch 37/50\n",
            "108000/108000 [==============================] - 3s 28us/step - loss: 0.0305 - mean_absolute_error: 0.0305 - val_loss: 0.5716 - val_mean_absolute_error: 0.5716\n",
            "Epoch 38/50\n",
            "108000/108000 [==============================] - 3s 29us/step - loss: 0.0285 - mean_absolute_error: 0.0285 - val_loss: 0.5671 - val_mean_absolute_error: 0.5671\n",
            "Epoch 39/50\n",
            "108000/108000 [==============================] - 3s 28us/step - loss: 0.0333 - mean_absolute_error: 0.0333 - val_loss: 0.5279 - val_mean_absolute_error: 0.5279\n",
            "Epoch 40/50\n",
            "108000/108000 [==============================] - 3s 28us/step - loss: 0.0285 - mean_absolute_error: 0.0285 - val_loss: 0.5618 - val_mean_absolute_error: 0.5618\n",
            "Epoch 41/50\n",
            "108000/108000 [==============================] - 3s 29us/step - loss: 0.0354 - mean_absolute_error: 0.0354 - val_loss: 0.5502 - val_mean_absolute_error: 0.5502\n",
            "Epoch 42/50\n",
            "108000/108000 [==============================] - 3s 29us/step - loss: 0.0289 - mean_absolute_error: 0.0289 - val_loss: 0.5211 - val_mean_absolute_error: 0.5211\n",
            "Epoch 43/50\n",
            "108000/108000 [==============================] - 3s 29us/step - loss: 0.0323 - mean_absolute_error: 0.0323 - val_loss: 0.5269 - val_mean_absolute_error: 0.5269\n",
            "Epoch 44/50\n",
            "108000/108000 [==============================] - 3s 30us/step - loss: 0.0313 - mean_absolute_error: 0.0313 - val_loss: 0.5618 - val_mean_absolute_error: 0.5618\n",
            "Epoch 45/50\n",
            "108000/108000 [==============================] - 3s 29us/step - loss: 0.0292 - mean_absolute_error: 0.0292 - val_loss: 0.5350 - val_mean_absolute_error: 0.5350\n",
            "Epoch 46/50\n",
            "108000/108000 [==============================] - 3s 28us/step - loss: 0.0339 - mean_absolute_error: 0.0339 - val_loss: 0.5553 - val_mean_absolute_error: 0.5553\n",
            "Epoch 47/50\n",
            "108000/108000 [==============================] - 3s 28us/step - loss: 0.0245 - mean_absolute_error: 0.0245 - val_loss: 0.5129 - val_mean_absolute_error: 0.5129\n",
            "Epoch 48/50\n",
            "108000/108000 [==============================] - 3s 29us/step - loss: 0.0298 - mean_absolute_error: 0.0298 - val_loss: 0.5805 - val_mean_absolute_error: 0.5805\n",
            "Epoch 49/50\n",
            "108000/108000 [==============================] - 3s 28us/step - loss: 0.0327 - mean_absolute_error: 0.0327 - val_loss: 0.5765 - val_mean_absolute_error: 0.5765\n",
            "Epoch 50/50\n",
            "108000/108000 [==============================] - 3s 28us/step - loss: 0.0234 - mean_absolute_error: 0.0234 - val_loss: 0.5692 - val_mean_absolute_error: 0.5692\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-498c5e9340c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;31m# serialize weights to HDF5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: Failed to fetch"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MabbaGxkR6oG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "15009163-eb6d-464f-aa83-f79f1f8a6a5c"
      },
      "source": [
        "np.squeeze(yscaler.inverse_transform(model.predict(X_check_emsc)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([58.029102, 74.650276, 61.961594, 73.57998 , 68.29044 , 67.304   ,\n",
              "       66.07796 , 65.72936 , 63.495   , 50.84944 , 45.497314, 47.78563 ,\n",
              "       50.859802, 68.13995 , 62.0005  , 50.62425 , 58.09921 , 61.399555,\n",
              "       68.85865 , 61.731323, 71.67718 , 69.25027 , 77.62508 , 65.57805 ,\n",
              "       82.34203 , 71.26531 , 71.26531 , 64.81685 , 60.961563, 53.25929 ,\n",
              "       68.28605 , 79.03267 , 76.17261 , 76.2956  , 83.75631 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePhAIBPNih5s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "20cf8437-87d9-4c22-cf49-4c80deccbf1f"
      },
      "source": [
        "np.squeeze(yscaler.inverse_transform(y_check))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([53., 53., 53., 80., 80., 80., 71., 71., 71., 65., 65., 65., 63.,\n",
              "       63., 63., 55., 55., 55., 82., 82., 82., 65., 65., 65., 73., 73.,\n",
              "       73., 67., 67., 67., 57., 57., 57., 84., 84.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    }
  ]
}